{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b7cf7a",
   "metadata": {},
   "source": [
    "# 스태킹 앙상블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f9d59",
   "metadata": {},
   "source": [
    "## 1. 기본 스태킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01cc99fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 데이터 불러오기(암 데이터)\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "cancer_data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a418c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = cancer_data.data\n",
    "y_label = cancer_data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_label, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9276936f",
   "metadata": {},
   "source": [
    "### 1) 알고리즘 객체 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04f3f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스태킹에 사용될 머신러닝 알고리즘 클래스 생성\n",
    "# KNN, 랜덤포레스트, 결정트리, 에이다부스트 사용\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=4) # 근처 개수 n만큼 뽑아 분류(4개중 3개가 1, 1개가 0이면 1로 분류)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "# 메타모델 (스태킹으로 만들어진 데이터 세트를 학습, 예측할 최종 모델)\n",
    "lr_final = LogisticRegression(C=10) # 규제 강도를 결정하는 파라미터 (c값이 낮을 수록 계수를 0으로 근사, regularization 강화)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb699f5",
   "metadata": {},
   "source": [
    "### 2) 개별 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb5226e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf.fit(X_train, y_train)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397f606c",
   "metadata": {},
   "source": [
    "### 3) 개별 모델의 예측 데이터 추출 / 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a1d4ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 데이터\n",
      "KNN예측데이터: [0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1\n",
      " 0 0 1] \n",
      "\n",
      "랜덤 포레스트 예측데이터: [0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 0 1] \n",
      "\n",
      "Decissiontree 예측데이터: [0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 1 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1\n",
      " 0 0 1] \n",
      "\n",
      "에디다부스트 예측데이터: [0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1\n",
      " 0 0 1] \n",
      "\n",
      "정확도 평가\n",
      "KNN 정확도: 0.9210526315789473 \n",
      "\n",
      "랜덤 포레스트 정확도: 0.9649122807017544 \n",
      "\n",
      "Decissiontree 정확도: 0.9122807017543859 \n",
      "\n",
      "에디다부스트 정확도: 0.956140350877193 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_pred = knn_clf.predict(X_test)\n",
    "knn_acc = accuracy_score(y_test, knn_pred)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "dt_acc = accuracy_score(y_test, dt_pred)\n",
    "ada_pred = ada_clf.predict(X_test)\n",
    "ada_acc = accuracy_score(y_test, ada_pred)\n",
    "\n",
    "print('예측 데이터')\n",
    "print(f'KNN예측데이터: {knn_pred}', '\\n')\n",
    "print(f'랜덤 포레스트 예측데이터: {rf_pred}', '\\n')\n",
    "print(f'Decissiontree 예측데이터: {dt_pred}', '\\n')\n",
    "print(f'에디다부스트 예측데이터: {ada_pred}', '\\n')\n",
    "\n",
    "print('정확도 평가')\n",
    "print(f'KNN 정확도: {knn_acc}', '\\n')\n",
    "print(f'랜덤 포레스트 정확도: {rf_acc}', '\\n')\n",
    "print(f'Decissiontree 정확도: {dt_acc}', '\\n')\n",
    "print(f'에디다부스트 정확도: {ada_acc}', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6146417f",
   "metadata": {},
   "source": [
    "### 4) 메타 데이터 생성 (예측값을 칼럼 레벨로 옆으로 붙여 피처 값으로 생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e64ce3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 114)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "        0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "        0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "        1, 0, 0, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "        0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "        1, 0, 0, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "        0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "        1, 0, 0, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
    "print(pred.shape)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12e4e050",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 1, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 1, 1, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행과 열 위치 교환 (transpose 사용)\n",
    "pred = np.transpose(pred)\n",
    "print(pred.shape)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05593e62",
   "metadata": {},
   "source": [
    "### 5) 메타모델 학습/ 예측/ 평가\n",
    "최종 데이터 세트를 최종 메타 모델로 형성한 객체에 넣어줌 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cc75667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타모델의 예측 정확도: 0.974\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(pred, y_test) # pred값이 변수로 들어가고 y_test가 결과(종속변수)로 들어가 훈련\n",
    "final = lr_final.predict(pred) # 각 개별 그룹에서 나타난 예측값으로 최종 예측값을 다시 예측\n",
    "\n",
    "print(f'최종 메타모델의 예측 정확도: {accuracy_score(y_test, final):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ed56ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5971cd72",
   "metadata": {},
   "source": [
    "=> 개별모델 정확도보다 향상됨 (동일한 데이터를 가지고 수행했기 때문에 과적합 발생 할 수 있음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f5a9be",
   "metadata": {},
   "source": [
    "#### 과제_09_23\n",
    "CV 세트 기반의 스태킹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27565bd4",
   "metadata": {},
   "source": [
    "## 2. CV세트 기반의 스태킹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55acf635",
   "metadata": {},
   "source": [
    "### 1) K폴드로 교차 검증 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aacfcde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "X_data = cancer_data.data\n",
    "y_label = cancer_data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_label, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193ff633",
   "metadata": {},
   "source": [
    "#### 개별 데이터를 위한 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256e9152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스태킹에 사용될 머신러닝 알고리즘 클래스 생성\n",
    "# KNN, 랜덤포레스트, 결정트리, 에이다부스트 사용\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=4) # 근처 개수 n만큼 뽑아 분류(4개중 3개가 1, 1개가 0이면 1로 분류)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "# 메타모델 (스태킹으로 만들어진 데이터 세트를 학습, 예측할 최종 모델)\n",
    "lr_final = LogisticRegression(C=10) # 규제 강도를 결정하는 파라미터 (c값이 낮을 수록 계수를 0으로 근사, regularization 강화)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c64aca",
   "metadata": {},
   "source": [
    "#### k폴드 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "875983d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------폴드 예측 값 (KNN모델 적용)------------------------------ \n",
      "\n",
      "#####1번째 폴드내부 예측값#####\n",
      "[1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 0 0 1 1 1\n",
      " 1 1 1 1 0 1 0 1 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1\n",
      " 0 1 1 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1\n",
      " 1 1 0 1 0 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 1 1 1 0 0 0 1 0 1 1 0\n",
      " 1 1 1 1]\n",
      "#####1번째 폴드외부 예측값#####\n",
      "[0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 0 1]\n",
      "#####2번째 폴드내부 예측값#####\n",
      "[1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 1 0 0 1 0 1 1 1\n",
      " 1 0 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 1 0 1\n",
      " 0 1 0 0 1 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1\n",
      " 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 1\n",
      " 0 0 1 1]\n",
      "#####2번째 폴드외부 예측값#####\n",
      "[0 1 1 0 1 1 1 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1\n",
      " 0 0 1]\n",
      "#####3번째 폴드내부 예측값#####\n",
      "[1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 0 0 1\n",
      " 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1\n",
      " 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 0 0 0 1\n",
      " 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0\n",
      " 1 1 1]\n",
      "#####3번째 폴드외부 예측값#####\n",
      "[0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 1\n",
      " 0 0 1]\n",
      "3폴드 전체 메타모델 학습용\n",
      "[[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "3폴드 전체 메타모델 test용\n",
      "[[0.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.33333333]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [0.33333333]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [0.33333333]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [1.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# k폴드 객체 생성 (cv=3으로 두고) 1개의 모델을 수행했을 때 최종 출력 값\n",
    "kfold = KFold(n_splits=3, shuffle=False) # shuffle : 데이터 분할하기전에 섞을지 말지 결정\n",
    "\n",
    "# 학습 후 예측값을 저장할 데이터 \n",
    "train_fold_pred = np.zeros((X_train.shape[0], 1)) #(메타모델 학습용)\n",
    "test_pred = np.zeros((X_test.shape[0], 3)) # (메타모델 test용)\n",
    "\n",
    "n_iter = 0\n",
    "print('------------------------------폴드 예측 값 (KNN모델 적용)------------------------------', '\\n')\n",
    "# K폴드로 나눈 데이터 추출해보기\n",
    "for train_index, test_index in kfold.split(X_train): # 훈련 데이터 안에서 k개의 폴드 데이터 세트로 분리(index 개수만 추출)\n",
    "    X_k_train, X_k_test = X_train[train_index], X_train[test_index] \n",
    "    y_k_train, y_k_test = y_train[train_index], y_train[test_index]  #훈련용 테스트용 따로 추출\n",
    "    \n",
    "    # 학습\n",
    "    knn_clf.fit(X_k_train, y_k_train)\n",
    "    \n",
    "    # 폴드 세트 내부에서 예측\n",
    "    knn_pred = knn_clf.predict(X_k_test)\n",
    "    \n",
    "    # 최종 X_test값으로 예측\n",
    "    knn_total_pred = knn_clf.predict(X_test)\n",
    "    \n",
    "    n_iter+=1\n",
    "    \n",
    "    # 폴드 내부 예측값\n",
    "    print(f'#####{n_iter}번째 폴드내부 예측값#####')\n",
    "    print(knn_pred)\n",
    "    \n",
    "    # 폴드 외부(원본 테스트 세트) 예측값\n",
    "    print(f'#####{n_iter}번째 폴드외부 예측값#####')\n",
    "    print(knn_total_pred)\n",
    "    \n",
    "    # 최종 knn모델을 적용한 메타모델 학습 데이터 \n",
    "    train_fold_pred[test_index, :] = knn_pred.reshape(-1, 1)\n",
    "        \n",
    "    # 폴드 외부에서 각 다른 모델로 수행한 예측 값을 합쳐서 최종 메타모델에서 사용할 테스트 데이터 후보로 추가(나중에 한번에 평균)\n",
    "    test_pred[:, n_iter-1] = knn_total_pred\n",
    "\n",
    "print('3폴드 전체 메타모델 학습용')\n",
    "print(train_fold_pred)\n",
    "print('3폴드 전체 메타모델 test용')\n",
    "print(np.mean(test_pred, axis=1).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c21c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 모델을 학습하여 예측데이터를 반환하는 함수 생성\n",
    "\n",
    "def get_stacking_base_datasets(model, X_train_, y_train_, X_test_, n_folds):\n",
    "    kfold = KFold(n_splits=n_folds, shuffle=False)\n",
    "    \n",
    "    # 메타모델 학습용, 테스트용 담을 빈 배열 생성\n",
    "    train_fold_pred = np.zeros((X_train_.shape[0], 1))\n",
    "    test_pred = np.zeros((X_test_.shape[0], n_folds))\n",
    "    print(f'{model}모델 시작')\n",
    "    \n",
    "    count = 0\n",
    "    for train_index, test_index in kfold.split(X_train_):\n",
    "        # 입력한 학습 데이터에서 위에서 각각 다른 모델로 생성한 객체에 학습/예측할 폴드 데이터 세트 추출\n",
    "        print('\\t 폴드 세트:', count, '시작')\n",
    "        X_tr = X_train_[train_index]\n",
    "        y_tr = y_train_[train_index]\n",
    "        X_te = X_train_[test_index]\n",
    "        \n",
    "        # 폴드 세트 내부에서 학습데이터로 모델 학습\n",
    "        model.fit(X_tr, y_tr)\n",
    "        \n",
    "        # 폴드 세트 내부에서 예측\n",
    "        train_fold_pred[test_index, :] = model.predict(X_te).reshape(-1, 1)\n",
    "        # 원본 테스트 데이터로 예측\n",
    "        test_pred[:, count] = model.predict(X_test_) # 각 열별로 담아서 나중에 한번에 평균 추출\n",
    "        \n",
    "        count+=1\n",
    "    \n",
    "    # 메타모델 테스트 용 최종 추출(평균)\n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1, 1)\n",
    "    \n",
    "    # 최종 메타모델에 사용할 학습용 데이터, 테스트용 데이터 순서대로 추출\n",
    "    return train_fold_pred, test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0777bbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=4)모델 시작\n",
      "\t 폴드 세트: 0 시작\n",
      "\t 폴드 세트: 1 시작\n",
      "\t 폴드 세트: 2 시작\n",
      "\t 폴드 세트: 3 시작\n",
      "\t 폴드 세트: 4 시작\n",
      "\t 폴드 세트: 5 시작\n",
      "\t 폴드 세트: 6 시작\n",
      "RandomForestClassifier(random_state=0)모델 시작\n",
      "\t 폴드 세트: 0 시작\n",
      "\t 폴드 세트: 1 시작\n",
      "\t 폴드 세트: 2 시작\n",
      "\t 폴드 세트: 3 시작\n",
      "\t 폴드 세트: 4 시작\n",
      "\t 폴드 세트: 5 시작\n",
      "\t 폴드 세트: 6 시작\n",
      "DecisionTreeClassifier()모델 시작\n",
      "\t 폴드 세트: 0 시작\n",
      "\t 폴드 세트: 1 시작\n",
      "\t 폴드 세트: 2 시작\n",
      "\t 폴드 세트: 3 시작\n",
      "\t 폴드 세트: 4 시작\n",
      "\t 폴드 세트: 5 시작\n",
      "\t 폴드 세트: 6 시작\n",
      "AdaBoostClassifier(n_estimators=100)모델 시작\n",
      "\t 폴드 세트: 0 시작\n",
      "\t 폴드 세트: 1 시작\n",
      "\t 폴드 세트: 2 시작\n",
      "\t 폴드 세트: 3 시작\n",
      "\t 폴드 세트: 4 시작\n",
      "\t 폴드 세트: 5 시작\n",
      "\t 폴드 세트: 6 시작\n"
     ]
    }
   ],
   "source": [
    "# 모델별로 데이터 추출\n",
    "\n",
    "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, 7)\n",
    "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 7)\n",
    "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test, 7)\n",
    "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5608ed82",
   "metadata": {},
   "source": [
    "### 2) 최종 메타모델 형성(각 모델의 메타모델 데이터 합치기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b0644831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 학습 피처 데이터 모양:  (455, 30) 원본 테스트 피처 모양:  (114, 30)\n",
      "스태킹 학습 피처 데이터 모양:  (455, 4) 스태킹 테스트 피처 데이터 모양:  (114, 4)\n"
     ]
    }
   ],
   "source": [
    "Stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)\n",
    "Stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)\n",
    "\n",
    "print('원본 학습 피처 데이터 모양: ', X_train.shape, '원본 테스트 피처 모양: ', X_test.shape)\n",
    "\n",
    "print('스태킹 학습 피처 데이터 모양: ', Stack_final_X_train.shape, '스태킹 테스트 피처 데이터 모양: ', Stack_final_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d00d70",
   "metadata": {},
   "source": [
    "=> 원본 데이터와 스티킹 학습을 통한 데이터 모양은 행 개수는 같으나 열 개수가 다름(4개의 개별 모델 데이터를 합쳐서 4개의 열이 생성됨)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c094041",
   "metadata": {},
   "source": [
    "### 3) 최종 메타모델 학습 후 예측/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a2a248c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 메타모델 정확도: 0.974\n"
     ]
    }
   ],
   "source": [
    "lr_final.fit(Stack_final_X_train, y_train)\n",
    "stack_final = lr_final.predict(Stack_final_X_test)\n",
    "total_accuracy = accuracy_score(y_test, stack_final)\n",
    "\n",
    "print(f'최종 메타모델 정확도: {total_accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2156d86e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
